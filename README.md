# Suivi de mouvement dans une vidéo.
Conception et développement d'application de suivi de mouvement dans une vidéo sous Keras et TensorFlow.
---
---
# Pré-requis: 

> Execution sur Jupyter/colab sous runtime GPU  
> tensorflow-gpu==1.14  
> Keras==2.3.1  

---
---
L'hiérarchie des fichiers requise: 
![alt text](https://github.com/BMouhcine/RT-Object-Detection/blob/master/781974614.jpg?raw=true)
---
---


# Utilisation:


1) ###    Prédiction


Pour la prédiction, ouvrir le *notebook* `predict.ipynb` et éxecuter les cellules. Le *notebook* est déjà commenté.


2) ###    Entraînement:
Pour la prédiction, ouvrir le *notebook* `train.ipynb` et éxecuter les cellules. Le *notebook* est déjà commenté.

3) ###    Modèle pré-entrainés:
Le lien vers le modèle chargé des poids pré-entraînés: [YOLOv3-Keras-Model](https://drive.google.com/file/d/1-57r1SHbGcfKJDXSv1I_NaeR13A8_6Dk/view?usp=sharing)

4) ###    Poids pré-entraînés:
Le lien vers les poids pré-entraînés: [YOLOv3-Keras-Weights](https://drive.google.com/file/d/1dOgWh0qGoatspBisG31fF1SpWVQ-jxZe/view?usp=sharing)

5) ###    MS COCO Dataset: 
Le lien vers la dataset utilisé pour entraîner les poids dans le point (3.): [MS COCO](http://cocodataset.org/)

6) ###    Drone Dataset: 
Extraite de Kaggle et pré-traitée pour avoir les annotations de format txt. adapté à YOLO: [Drone-dataset-uav](https://drive.google.com/file/d/1n5r4TSCzd9oT1Dc7sE3kY9vT3KJEBCQH/view?usp=sharing)

