{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SQ0T0D-CECc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4903f78c-224c-4e39-d476-569f5e9f9ff6"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldOlMV-F0QvD",
        "colab_type": "text"
      },
      "source": [
        "### Importer les packages nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMG8FgBNiX3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from train.build_train import preprocess_true_boxes, build_model_net, yolo_loss\n",
        "from train.train_util import get_random_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flzXaIYxzxYJ",
        "colab_type": "text"
      },
      "source": [
        "### Copier la Dataset du drone et les poids pré-entraînés sur MS COCO depuis le drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kpMPK3iH8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copier la dataset depuis le drive.\n",
        "!cp drive/\"My Drive\"/amodelzzz/drone_dataset.zip ./\n",
        "# Copier les poids entrainés sur MS COCO depuis le drive\n",
        "!cp drive/\"My Drive\"/amodelzzz/model_weights_only.h5 .\n",
        "# Décompresser la dataset et supprimer le fichier zip.\n",
        "!unzip drone_dataset.zip\n",
        "!rm drone_dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkOdMPkK1hD8",
        "colab_type": "text"
      },
      "source": [
        "### Définir une fonction qui lit les coordonnées des anchors boxes depuis un txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aUpvwWP1gkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_anchors(anchors_path):\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyjmGlfL1o8E",
        "colab_type": "text"
      },
      "source": [
        "### Définir une fonction qui prépare créée et prépare le modèle pour l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGnQsVWRjeO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape, anchors, num_classes, weights_path='model_weights_only.h5'):\n",
        "    K.clear_session() \n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "    \"\"\"\n",
        "     Création du placeholder 'y_true' qui va contenir les 3 outputs du model.\n",
        "     Les 3 outputs du model seront de taille 52, 26 et 13.\n",
        "     Les 3 outputs du model seront respectivement au niveau des layers: 82, 94 et 106.\n",
        "   \"\"\"\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "    # Création de l'architecture du model.\n",
        "    model_body = build_model_net()\n",
        "    print('On a créé le model ayant {} anchors et {} classes d\\'objets.'.format(num_anchors, num_classes))\n",
        "    \n",
        "    # Charger les weights. (pre-trained weights)\n",
        "    model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "    print('On a chargé les Weights initiaux. {}.'.format(weights_path))\n",
        "    \n",
        "    \n",
        "    # Bloquer toute les couches du modèle et laisser les 3 couches de sorties.\n",
        "    num = len(model_body.layers)-3\n",
        "    for i in range(num):\n",
        "      model_body.layers[i].trainable = False\n",
        "    # Configurer la fonction loss comme layer Lambda sous nom: yolo_loss.\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': .5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        " \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXERI5Tf4JvQ",
        "colab_type": "text"
      },
      "source": [
        "### Définir la fonction data_generator qui pré-traîte les données pour le training.\n",
        "Ainsi que distordre les images via la fonction `get_random_data` avec les paramètres :\n",
        "jitter=0.3, hue=0.1 et saturation=1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKJCDhLT4JOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data('drone_dataset_yolo/dataset_txt/'+annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        " \n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_p1XM82D1kq",
        "colab_type": "text"
      },
      "source": [
        "### Définir une fonction qui lit les labels(catégories ou classes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHSJnDTkm0LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_labels(f):\n",
        "  labels_file = open(f,'r')\n",
        "  labels_list = labels_file.read().split('\\n')\n",
        "  labels_list.pop()\n",
        "  return labels_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA0peQF4D5hS",
        "colab_type": "text"
      },
      "source": [
        "### sauvegarder les liens vers le fichier d'annotations, d'anchors et des classes. Ainsi que l'input shape qui est la taille de l'image d'entrée imposée par le modèle.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIPk3xF9lBnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotation_path = 'annots.txt' # accès aux annotations.\n",
        "# lire les labels depuis un fichier texte. (MSCOCO labels)\n",
        "labels = read_labels('labels.txt')\n",
        "anchors_filename = 'anchors.txt' # path pour lire anchors.\n",
        "# on sauvgarde le nombre de classes (qui est 80).\n",
        "num_classes = len(labels)\n",
        "# lisons les anchors depuis le fichier des anchors.\n",
        "anchors = get_anchors(anchors_filename)\n",
        "input_shape=(416,416)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3YqJN6VENYw",
        "colab_type": "text"
      },
      "source": [
        "### Créer un modèle au préalable chargé des poids pré-entraînés.\n",
        "Aussi, bloquer toutes les couches sauf les 3 couches de sorties qui sont déstinées à s'entraîner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNGd-gWvlCHK",
        "colab_type": "code",
        "outputId": "b49093a4-bb68-4eab-f736-8fabd16fb5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = create_model(input_shape, anchors, num_classes, weights_path='model_weights_only.h5')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On a créé le model ayant 9 anchors et 80 classes d'objets.\n",
            "On a chargé les Weights initiaux. model_weights_only.h5.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFencEy3Ehik",
        "colab_type": "text"
      },
      "source": [
        "### Détermination du nombre du lot de training/lot de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoqTc685lHIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_split = 0.2 # lot de validation a pour portion 20%.\n",
        "with open(annotation_path) as f:\n",
        "    lines = f.readlines()\n",
        "np.random.seed(33)\n",
        "np.random.shuffle(lines)\n",
        "np.random.seed(None)\n",
        "num_val = int(len(lines)*val_split)\n",
        "num_train = len(lines) - num_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWuI99n6EvBL",
        "colab_type": "text"
      },
      "source": [
        "### Lancer le training en utilisant l'optimisateur Adam de learning_rate=0.001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUSiQuPlJZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utiliser la fonction loss qu'on a définit sous le nom : yolo_loss.\n",
        "# Utiliser Adam comme optimisateur avec un learning_rate alpha = .001\n",
        "model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        " \n",
        "batch_size = 32\n",
        "print('Faire le training du model sur {} échantillions, validation sur {} échantillions, avec un batch size {}.'.format(num_train, num_val, batch_size))\n",
        "model.fit_generator(\n",
        "    # Fournir le data_generator.\n",
        "    data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "        # Fournir la longueur de chaque epoch.\n",
        "        steps_per_epoch=max(1, num_train//batch_size),\n",
        "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "        # FOurnir la longueur de chaque validation.\n",
        "        validation_steps=max(1, num_val//batch_size),\n",
        "        # on va utiliser 750 epochs.\n",
        "        epochs=750,\n",
        "        # En commençant par l'epoch 0.\n",
        "        initial_epoch=0)\n",
        "# Sauvegarder les weights sous fichier .h5 (format de keras).\n",
        "model.save_weights('trained_weights_stage_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCX14nAWoYc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}